
1. python -m -venv venv 建立虚拟环境
2. cd venv/Script
3. activate
    * pip install scrapy
    * pip install Twisted-18.4.0-cp36-cp36m-win_amd64.whl
4. scrapy startproject douban
5. scrapy genspider movie movie.doouban.com  # 爬虫名和起始url
6. scrapy shell 'url' 交互式爬虫
    * response.xpath('//*[@id="content"]/div/div[1]/ol/li') 测试
7.scrapy crawl movie -o result.json 框架，爬取，文件，方式，格式

1. movie.py  爬取网页，内容，url.
2. pipelines.py  持久化操作
3. items.py  需要保存的网页部分
4. Spider就是您定义爬取的动作及分析某个网页(或者是有些网页)的地方。
5. 对spider来说，爬取的循环类似下文:
    1. 以初始的URL初始化Request，并设置回调函数。 当该request下载完毕并返回时，将生成response，并作为参数传给该回调函数。
    * spider中初始的request是通过调用 start_requests() 来获取的。 start_requests() 读取 start_urls 中的URL， 并以 parse 为回调函数生成 Request 。
    2. 在回调函数内分析返回的(网页)内容，返回 Item 对象或者 Request 或者一个包括二者的可迭代容器。 返回的Request对象之后会经过Scrapy处理，下载相应的内容，并调用设置的callback函数(函数可相同)。
    3. 在回调函数内，您可以使用 选择器(Selectors) (您也可以使用BeautifulSoup, lxml 或者您想用的任何解析器) 来分析网页内容，并根据分析的数据生成item。
    4. 最后，由spider返回的item将被存到数据库(由某些 Item Pipeline 处理)或使用 Feed exports 存入到文件中。

